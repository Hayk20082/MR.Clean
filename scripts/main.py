import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, models, transforms
import os

DATA_DIR = r'C:\Users\hayk\Downloads\ai_proj\data'
MODEL_SAVE_DIR = r'C:\Users\hayk\Downloads\ai_proj\models'
os.makedirs(MODEL_SAVE_DIR, exist_ok=True)

IMG_HEIGHT = 224
IMG_WIDTH = 224
BATCH_SIZE = 4
EPOCHS = 100
NUM_CLASSES = 4
LEARNING_RATE = 0.0001

EARLY_STOP_DELTA = 0.0001
EARLY_STOP_PATIENCE = 25

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),
        transforms.RandomRotation(20),
        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), shear=0.2, scale=(0.8, 1.2)),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
        transforms.RandomGrayscale(p=0.1),
        transforms.GaussianBlur(kernel_size=(3, 7), sigma=(0.1, 2.0)),
        transforms.RandomPosterize(bits=4, p=0.1),
        transforms.RandomSolarize(threshold=192.0, p=0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
}

image_datasets = {
    'train': datasets.ImageFolder(os.path.join(DATA_DIR, 'train'), transform=data_transforms['train']),
    'val': datasets.ImageFolder(os.path.join(DATA_DIR, 'val'), transform=data_transforms['val'])
}

dataloaders = {
    'train': DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, shuffle=True),
    'val': DataLoader(image_datasets['val'], batch_size=BATCH_SIZE, shuffle=False)
}

dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}

class CustomVGG16(nn.Module):
    def __init__(self, num_classes):
        super(CustomVGG16, self).__init__()
        self.features = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1).features
        for param in self.features.parameters():
            param.requires_grad = False
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(512, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = self.classifier(x)
        return x

model = CustomVGG16(NUM_CLASSES).to(device)

def categorical_crossentropy(outputs, targets_onehot):
    log_probs = torch.log_softmax(outputs, dim=1)
    loss = -(targets_onehot * log_probs).sum(dim=1).mean()
    return loss

optimizer = optim.Adam(model.classifier.parameters(), lr=LEARNING_RATE)

best_val_loss = float("inf")
epochs_no_improve = 0

for epoch in range(EPOCHS):
    epoch_start = time.time()
    print(f"\n–≠–ø–æ—Ö–∞ {epoch+1}/{EPOCHS}")
    print("-" * 20)

    history = {}

    for phase in ['train', 'val']:
        if phase == 'train':
            model.train()
        else:
            model.eval()

        running_loss = 0.0
        running_corrects = 0

        for inputs, labels in dataloaders[phase]:
            inputs, labels = inputs.to(device), labels.to(device)
            labels_onehot = torch.nn.functional.one_hot(labels, NUM_CLASSES).float().to(device)

            optimizer.zero_grad()
            with torch.set_grad_enabled(phase == 'train'):
                outputs = model(inputs)
                loss = categorical_crossentropy(outputs, labels_onehot)
                _, preds = torch.max(outputs, 1)

                if phase == 'train':
                    loss.backward()
                    optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / dataset_sizes[phase]
        epoch_acc = running_corrects.double().item() / dataset_sizes[phase]

        history[f"{phase}_loss"] = epoch_loss
        history[f"{phase}_acc"] = epoch_acc

        print(f"{phase}: Loss={epoch_loss:.4f} | Acc={epoch_acc:.4f}")

    epoch_time = time.time() - epoch_start
    print(f"‚è± –í—Ä–µ–º—è —ç–ø–æ—Ö–∏: {epoch_time:.2f} —Å–µ–∫")

    if history['val_loss'] + EARLY_STOP_DELTA < best_val_loss:
        print("üî• –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å (–ø–æ loss)!")
        best_val_loss = history['val_loss']
        epochs_no_improve = 0

        torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, "best_model.pth"))
        print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: best_model.pth")

    else:
        epochs_no_improve += 1
        print(f"‚ö†Ô∏è –ù–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è ({epochs_no_improve}/{EARLY_STOP_PATIENCE})")

        if epochs_no_improve >= EARLY_STOP_PATIENCE:
            print("\nüõë Early Stopping: –æ–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ!")
            break

torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, "last_epoch.pth"))
print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: last_epoch.pth")
print("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
