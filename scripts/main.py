import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, models, transforms
import os

# --- 1. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ---
DATA_DIR = r'C:\Users\hayk\Downloads\ai_proj\data'
MODEL_SAVE_DIR = r'C:\Users\hayk\Downloads\ai_proj\models'
os.makedirs(MODEL_SAVE_DIR, exist_ok=True)

IMG_HEIGHT = 224
IMG_WIDTH = 224
BATCH_SIZE = 4
EPOCHS = 100
NUM_CLASSES = 4
LEARNING_RATE = 0.0001

EARLY_STOP_DELTA = 0.0001    # –µ—Å–ª–∏ loss –º–µ–Ω—è–µ—Ç—Å—è –º–µ–Ω—å—à–µ —ç—Ç–æ–≥–æ ‚Üí —Å—Ç–æ–ø
EARLY_STOP_PATIENCE = 25     # —Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö —Ç–µ—Ä–ø–µ—Ç—å

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
# --- 2. DataLoader (–° –û–ë–ù–û–í–õ–ï–ù–ù–´–ú–ò –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–Ø–ú–ò) ---
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),

        # --- –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ---
        transforms.RandomRotation(20),
        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), shear=0.2, scale=(0.8, 1.2)),
        transforms.RandomHorizontalFlip(),

        # --- –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ü–≤–µ—Ç–∞ –∏ —Å—Ç–∏–ª—è (–í–∞—à —Ç–µ–∫—É—â–∏–π + –Ω–æ–≤—ã–µ) ---

        # –°–ª—É—á–∞–π–Ω–æ –∏–∑–º–µ–Ω—è–µ–º —è—Ä–∫–æ—Å—Ç—å, –∫–æ–Ω—Ç—Ä–∞—Å—Ç, –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å –∏ –æ—Ç—Ç–µ–Ω–æ–∫
        # –í–∞—à–∏ —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (0.3, 0.3, 0.3, 0.1) —É–∂–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–∏–ª—å–Ω—ã–µ
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),

        # –° –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é (p=0.1) –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –ß/–ë
        transforms.RandomGrayscale(p=0.1),

        # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–∫–æ–µ –ì–∞—É—Å—Å–æ–≤–æ —Ä–∞–∑–º—ã—Ç–∏–µ
        transforms.GaussianBlur(kernel_size=(3, 7), sigma=(0.1, 2.0)),

        # --- –î–û–ë–ê–í–õ–ï–ù–ù–´–ï (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –ø–æ–ª–µ–∑–Ω–æ) ---

        # "–ü–æ—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è": —É–º–µ–Ω—å—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∏—Ç –Ω–∞ —Ü–≤–µ—Ç–æ–≤–æ–π –∫–∞–Ω–∞–ª,
        # —á—Ç–æ "–æ–≥—Ä—É–±–ª—è–µ—Ç" —Ü–≤–µ—Ç–∞ –∏ –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å –Ω–µ —Ü–µ–ø–ª—è—Ç—å—Å—è –∑–∞ –º–µ–ª–∫–∏–µ —Ü–≤–µ—Ç–æ–≤—ã–µ –¥–µ—Ç–∞–ª–∏
        transforms.RandomPosterize(bits=4, p=0.1),

        # "–°–æ–ª—è—Ä–∏–∑–∞—Ü–∏—è": –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–∏–∫—Å–µ–ª–µ–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
        # –≠—Ç–æ –æ—á–µ–Ω—å "–Ω–µ–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è" –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ª–æ–º–∞–µ—Ç –ø—Ä–∏–≤—ã—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        transforms.RandomSolarize(threshold=192.0, p=0.1),
        # --- –ö–æ–Ω–µ—Ü –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö ---

        transforms.ToTensor(),  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    ]),
    'val': transforms.Compose([
        # ... (–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–µ—Ç –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
}
#

image_datasets = {
    'train': datasets.ImageFolder(os.path.join(DATA_DIR, 'train'), transform=data_transforms['train']),
    'val': datasets.ImageFolder(os.path.join(DATA_DIR, 'val'), transform=data_transforms['val'])
}

dataloaders = {
    'train': DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, shuffle=True),
    'val': DataLoader(image_datasets['val'], batch_size=BATCH_SIZE, shuffle=False)
}

dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
# --- 3. –ú–æ–¥–µ–ª—å ---
class CustomVGG16(nn.Module):
    def __init__(self, num_classes):
        super(CustomVGG16, self).__init__()
        self.features = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1).features
        for param in self.features.parameters():
            param.requires_grad = False
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(512, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = self.classifier(x)
        return x


model = CustomVGG16(NUM_CLASSES).to(device)

# --- 4. Loss –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä ---
def categorical_crossentropy(outputs, targets_onehot):
    log_probs = torch.log_softmax(outputs, dim=1)
    loss = -(targets_onehot * log_probs).sum(dim=1).mean()
    return loss

optimizer = optim.Adam(model.classifier.parameters(), lr=LEARNING_RATE)

# --- 5. –û–±—É—á–µ–Ω–∏–µ ---
best_val_loss = float("inf")
epochs_no_improve = 0

for epoch in range(EPOCHS):
    epoch_start = time.time()
    print(f"\n–≠–ø–æ—Ö–∞ {epoch+1}/{EPOCHS}")
    print("-" * 20)

    history = {}

    for phase in ['train', 'val']:
        if phase == 'train':
            model.train()
        else:
            model.eval()

        running_loss = 0.0
        running_corrects = 0

        for inputs, labels in dataloaders[phase]:
            inputs, labels = inputs.to(device), labels.to(device)
            labels_onehot = torch.nn.functional.one_hot(labels, NUM_CLASSES).float().to(device)

            optimizer.zero_grad()
            with torch.set_grad_enabled(phase == 'train'):
                outputs = model(inputs)
                loss = categorical_crossentropy(outputs, labels_onehot)
                _, preds = torch.max(outputs, 1)

                if phase == 'train':
                    loss.backward()
                    optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / dataset_sizes[phase]
        epoch_acc = running_corrects.double().item() / dataset_sizes[phase]

        history[f"{phase}_loss"] = epoch_loss
        history[f"{phase}_acc"] = epoch_acc

        print(f"{phase}: Loss={epoch_loss:.4f} | Acc={epoch_acc:.4f}")

    epoch_time = time.time() - epoch_start
    print(f"‚è± –í—Ä–µ–º—è —ç–ø–æ—Ö–∏: {epoch_time:.2f} —Å–µ–∫")

    # --- Early stopping ---
    if history['val_loss'] + EARLY_STOP_DELTA < best_val_loss:
        print("üî• –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å (–ø–æ loss)!")
        best_val_loss = history['val_loss']
        epochs_no_improve = 0

        torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, "best_model.pth"))
        print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: best_model.pth")

    else:
        epochs_no_improve += 1
        print(f"‚ö†Ô∏è –ù–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è ({epochs_no_improve}/{EARLY_STOP_PATIENCE})")

        if epochs_no_improve >= EARLY_STOP_PATIENCE:
            print("\nüõë Early Stopping: –æ–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ!")
            break

# —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é
torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, "last_epoch.pth"))
print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: last_epoch.pth")
print("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
